{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9ikEL1gJC89",
        "outputId": "cddcaf38-aa41-48ec-f465-3275c978d8e9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Corpus:\n",
            "['This is the first document.', 'Here is the second document.', 'And another document.']\n",
            "\n",
            "Corpus after removing tags:\n",
            "['This is the first document.', 'Here is the second document.', 'And another document.']\n",
            "\n",
            "Corpus after converting to lowercase:\n",
            "['this is the first document.', 'here is the second document.', 'and another document.']\n",
            "\n",
            "Corpus after removing stopwords:\n",
            "['this is the first document.', 'here is the second document.', 'and another document.']\n"
          ]
        }
      ],
      "source": [
        "# Import necessary libraries\n",
        "import re\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "# Sample data (replace this with your actual data)\n",
        "corpus = [\"This is the first document.\", \"Here is the second document.\", \"And another document.\"]\n",
        "labels = [1, 0, 1]  # 1 for positive class, 0 for negative class\n",
        "\n",
        "# Print the original corpus\n",
        "print(\"Original Corpus:\")\n",
        "print(corpus)\n",
        "\n",
        "# Basic Preprocessing\n",
        "# Remove tags\n",
        "def remove_tags(text):\n",
        "    clean = re.compile('<.*?>')\n",
        "    return re.sub(clean, '', text)\n",
        "\n",
        "corpus = [remove_tags(document) for document in corpus]\n",
        "\n",
        "# Print the corpus after removing tags\n",
        "print(\"\\nCorpus after removing tags:\")\n",
        "print(corpus)\n",
        "\n",
        "# Lowercase\n",
        "corpus = [document.lower() for document in corpus]\n",
        "\n",
        "# Print the corpus after converting to lowercase\n",
        "print(\"\\nCorpus after converting to lowercase:\")\n",
        "print(corpus)\n",
        "\n",
        "# Remove stopwords\n",
        "stopwords = set(['list', 'of', 'stop', 'words', 'to', 'remove'])\n",
        "corpus = [' '.join([word for word in document.split() if word not in stopwords]) for document in corpus]\n",
        "\n",
        "# Print the corpus after removing stopwords\n",
        "print(\"\\nCorpus after removing stopwords:\")\n",
        "print(corpus)\n",
        "\n",
        "# Applying Bag-of-Words (BoW)\n",
        "vectorizer = CountVectorizer()\n",
        "X_bow = vectorizer.fit_transform(corpus)\n",
        "\n",
        "# Applying TF-IDF\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "X_tfidf = tfidf_vectorizer.fit_transform(corpus)\n",
        "\n",
        "# ... (continue with the rest of your code)\n"
      ]
    }
  ]
}